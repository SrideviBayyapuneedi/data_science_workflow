{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Frame-the-Problem\" data-toc-modified-id=\"Frame-the-Problem-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Frame the Problem</a></span></li><li><span><a href=\"#Select-a-performance-measure\" data-toc-modified-id=\"Select-a-performance-measure-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Select a performance measure</a></span><ul class=\"toc-item\"><li><span><a href=\"#Regression-problems--PM\" data-toc-modified-id=\"Regression-problems--PM-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Regression problems -PM</a></span></li><li><span><a href=\"#Classification-Problems\" data-toc-modified-id=\"Classification-Problems-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Classification Problems</a></span><ul class=\"toc-item\"><li><span><a href=\"#Confusion-Matrix\" data-toc-modified-id=\"Confusion-Matrix-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Confusion Matrix</a></span></li></ul></li></ul></li><li><span><a href=\"#Check-Assumptions\" data-toc-modified-id=\"Check-Assumptions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Check Assumptions</a></span></li><li><span><a href=\"#Create-the-workspace-and-an-isolated-environment\" data-toc-modified-id=\"Create-the-workspace-and-an-isolated-environment-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Create the workspace and an isolated environment</a></span></li><li><span><a href=\"#Download-the-data:\" data-toc-modified-id=\"Download-the-data:-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Download the data:</a></span></li><li><span><a href=\"#Take-a-Quick-look-at-the-data-structure\" data-toc-modified-id=\"Take-a-Quick-look-at-the-data-structure-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Take a Quick look at the data structure</a></span></li><li><span><a href=\"#Create-a-test-set-and-training-set\" data-toc-modified-id=\"Create-a-test-set-and-training-set-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Create a test set and training set</a></span></li><li><span><a href=\"#Looking-for-correlations\" data-toc-modified-id=\"Looking-for-correlations-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Looking for correlations</a></span></li><li><span><a href=\"#Experiement-with-attribute-combinations\" data-toc-modified-id=\"Experiement-with-attribute-combinations-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Experiement with attribute combinations</a></span></li><li><span><a href=\"#Data-transformation\" data-toc-modified-id=\"Data-transformation-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Data transformation</a></span></li><li><span><a href=\"#Cleaning-data---Fill-missing-values\" data-toc-modified-id=\"Cleaning-data---Fill-missing-values-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Cleaning data - Fill missing values</a></span></li><li><span><a href=\"#Handling-text-and-categorical-data\" data-toc-modified-id=\"Handling-text-and-categorical-data-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Handling text and categorical data</a></span></li><li><span><a href=\"#Building-a-custom-class-to-do-custom-data-transformations\" data-toc-modified-id=\"Building-a-custom-class-to-do-custom-data-transformations-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Building a custom class to do custom data transformations</a></span></li><li><span><a href=\"#Feature-Scaling---very-important\" data-toc-modified-id=\"Feature-Scaling---very-important-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>Feature Scaling - very important</a></span></li><li><span><a href=\"#Creating-a-Pipeline\" data-toc-modified-id=\"Creating-a-Pipeline-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>Creating a Pipeline</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the Big Picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    a. Understand the business objective\n",
    "        What is the business objective? How does the company expect to use this model and benefit from this model?\n",
    "    b. Frame the problem into\n",
    "        i. Supervised Learning\n",
    "        ii. Unsupervised Learing\n",
    "        iii. Reinforcement Learning\n",
    "        iv. Batch learning or Online Learning\n",
    "        v. Instance based learning or model based learning\n",
    "    c. Is there a current model and how does it perform?\n",
    "    d. What is the process right now and why are we building the model only now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a performance measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression problems -PM\n",
    "    a. RMSE\n",
    "    b. MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check with different teams involved in the project if you have captured the points correctly and you are not making any assumptionsm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the workspace and an isolated environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data: \n",
    "1. Automate downloading the data, write a function\n",
    "2. If necessary write a function to read the data and set dtype of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a Quick look at the data structure\n",
    "Use the following commands\n",
    "1. df.head()\n",
    "2. df.info() to know the number of rows, columns and non-null values and datatypes of each column\n",
    "3. If you observe that there are categorical data columns, investigate to find the distribution of different categories\n",
    "4. For numerical columns, use the df.describe() to understand the centrality and deviation\n",
    "5. Plot a histogram of the numerical columns using df.hist(figsize=(20,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a test set and training set\n",
    "Create a test set and keep it aside and never look at it, to avoid data snooping error.\n",
    "1. If the dataset is fixed then you can use a non-hashing technique to split the test and train datasets\n",
    "2. If there is a chance that the dataset can be updated/refreshed from time to time then use a hashing based test and train set.\n",
    "3. The test set/validation set is usually 20% of all the training data\n",
    "\n",
    "Shuffling is of two types, random shuffling and stratified shuffling split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discover and Visualize the data using the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to keep in mind before we start exploring the data.\n",
    "1. Data exploration should be done on the training set only!!\n",
    "2. If the training set is large enough, sample the data to make exploration fast and easy\n",
    "3. Make sure exploration does not change the data in the training set, to avoid this, exploration could be done on a copy of the training dataset\n",
    "\n",
    "Play around with the visualization parameters to make patterns stand out\n",
    "\n",
    "This step should be thorogh and is iterative with all other steps below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the size of the dataset, calculate the correlation coefficient between every pair of attributes, especially between the dependent variable and the independent variable. Keep in mind that correlation only measures the linear relationship between the variables and would completly miss out the non-linear relationship. Plot the scatter plot for  the pair of variables to see the relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiement with attribute combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using domain knowledge, insights from the data visualization, create new interesting features to be used in the ML algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for ML Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. During the data exploration phase, if you find attributes with heavy tails, you might want to transform the data by computing their logirthm\n",
    "2. Clean any outliers, capped instances\n",
    "\n",
    "** This step needs to be done in the data exploration phase as well **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data - Fill missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the ML algorithms do not work wel when they have missing values. Below are few methods to fill missing values.\n",
    "1. Fill them with zero, median or mean. \n",
    "    - When using this technique make sure that you are storing the value being used to fill the null values in a variable, this same value needs to e used for filling the test set.\n",
    "    - Also think of strategies to fill missing values in the training data for all the columns even if they do not have any missing values right now\n",
    "\n",
    "2. Delete the rows with missing values, based on the % of missing values for an instance\n",
    "3. Delete an attribute, based on the % of the missing values for that attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling text and categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most ML algorithms work with numbers, we have to convert the text in categorical columns to numbers. \n",
    "- Mapping each category to a number is not the right way to do it since the machine learning algorithms will consider two near by values more similar than 2 distant values, which is not the case.\n",
    "- To overcom the issue mentioned above, we create a binary attribute for each category. This is also called one-hot encoding where only one of the binary attributes is hot and the others are cold\n",
    "- If we have a very large number of categories, this will create a very large table with zeroes and this will need a lot of memory. But to overcome this python creates a Scipy sparse matrix which only stores the location of the non-zero element.\n",
    "- If really required, the spare matrix can be converted to a dense numpy matrix\n",
    "- When the number of categories becomes too large, then it is best to use embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a custom class to do custom data transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a class and implement 3 methods fit, transform and fit_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling - very important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the ML algorithms do not perform well when the numerical attributes are of different scale.\n",
    "** Note that it is generally not required to scale the target variable **\n",
    "Two common ways of applying feature scaling, are:\n",
    "1. min-max scaling also called normalization\n",
    "    - **Pros**\n",
    "        -  Brings the data range between 0-1 which is more favorable, especially to neural networks\n",
    "    - **Cons**\n",
    "        -  Very sensitive to outliers since it uses min and max values of an attribute\n",
    "2. standardization\n",
    "    - **Pros**\n",
    "        -  Less susecptible to outliers\n",
    "    \n",
    "    - **Cons**\n",
    "         -  Does not bring down the data range between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pipeline that will take the dataset as an input and give the output as a transformed data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
